<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>マイクから音をリアルタイム再生する</title>
<style>
    body {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
        font-family: Arial, sans-serif;
    }
    button {
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
    }
</style>
</head>
<body>
<button id="startButton">音声を開始</button>
<button id="stopButton" disabled>音声を停止</button>
<br>
<div id="liveAudio"></div>

<script>
let audioContext;
let microphoneStream;
let scriptNode;
let audioBufferSourceNode;

async function startLiveAudio() {
    try {
        // Web Audio API の AudioContext を生成
        audioContext = new (window.AudioContext || window.webkitAudioContext)();

        // マイクから音声を取得するための getUserMedia を使ってストリームを取得
        microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // ストリームから音声データを取得するためのソースノードを作成
        const sourceNode = audioContext.createMediaStreamSource(microphoneStream);

        // 出力先の destination ノードを作成
        const destinationNode = audioContext.destination;

        // ScriptProcessorNode を作成して音声処理を行う
        scriptNode = audioContext.createScriptProcessor(4096, 1, 1);

        // ScriptProcessorNode で音声データを処理する処理を設定
        scriptNode.onaudioprocess = event => {
            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0); // 左チャンネルのデータのみ使用

            // データを再生するために AudioBuffer を作成
            const outputBuffer = audioContext.createBuffer(1, inputBuffer.length, audioContext.sampleRate);
            const outputData = outputBuffer.getChannelData(0);
            outputData.set(inputData);

            // 以前の再生があれば停止
            if (audioBufferSourceNode) {
                audioBufferSourceNode.stop();
            }

            // 出力先にデータを送る
            audioBufferSourceNode = audioContext.createBufferSource();
            audioBufferSourceNode.buffer = outputBuffer;
            audioBufferSourceNode.connect(destinationNode);
            audioBufferSourceNode.start();
        };

        // ソースノードを ScriptProcessorNode に接続
        sourceNode.connect(scriptNode);
        scriptNode.connect(destinationNode);

        // ボタンの状態を変更
        document.getElementById('startButton').disabled = true;
        document.getElementById('stopButton').disabled = false;
    } catch (error) {
        console.error('録音の許可が得られませんでした: ', error);
    }
}

function stopLiveAudio() {
    // ボタンの状態を変更
    document.getElementById('startButton').disabled = false;
    document.getElementById('stopButton').disabled = true;

    // ストリームを停止
    if (microphoneStream) {
        microphoneStream.getTracks().forEach(track => track.stop());
    }

    // コンテキストを閉じる
    if (audioContext) {
        audioContext.close();
    }

    // 再生中の音声を停止
    if (audioBufferSourceNode) {
        audioBufferSourceNode.stop();
    }
}

document.addEventListener('DOMContentLoaded', () => {
    document.getElementById('startButton').addEventListener('click', startLiveAudio);
    document.getElementById('stopButton').addEventListener('click', stopLiveAudio);
});
</script>
</body>
</html>
