<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>マイクから音をリアルタイム再生する</title>
<style>
    body {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
        font-family: Arial, sans-serif;
    }
    button {
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
    }
</style>
</head>
<body>
<button id="startButton">音声を開始</button>
<button id="stopButton" disabled>音声を停止</button>
<br>
<div id="liveAudio"></div>

<script>
let audioContext;
let microphoneStream;
let scriptNode;

function startLiveAudio() {
    // Web Audio API の AudioContext を生成
    audioContext = new (window.AudioContext || window.webkitAudioContext)();

    // マイクから音声を取得するための getUserMedia を使ってストリームを取得
    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            microphoneStream = stream;

            // ストリームから音声データを取得するためのソースノードを作成
            const sourceNode = audioContext.createMediaStreamSource(stream);

            // 出力先の destination ノードを作成
            const destinationNode = audioContext.destination;

            // ScriptProcessorNode を作成して音声処理を行う
            scriptNode = audioContext.createScriptProcessor(4096, 1, 1);

            // ScriptProcessorNode で音声データを処理する処理を設定
            scriptNode.onaudioprocess = event => {
                const inputBuffer = event.inputBuffer;
                const inputData = inputBuffer.getChannelData(0); // 左チャンネルのデータのみ使用

                // データを再生するために AudioBuffer を作成
                const outputBuffer = audioContext.createBuffer(1, inputBuffer.length, audioContext.sampleRate);
                const outputData = outputBuffer.getChannelData(0);
                outputData.set(inputData);

                // 出力先にデータを送る
                const audioBufferSourceNode = audioContext.createBufferSource();
                audioBufferSourceNode.buffer = outputBuffer;
                audioBufferSourceNode.connect(destinationNode);
                audioBufferSourceNode.start();
            };

            // ソースノードを ScriptProcessorNode に接続
            sourceNode.connect(scriptNode);
            scriptNode.connect(destinationNode);

            // ボタンの状態を変更
            document.getElementById('startButton').disabled = true;
            document.getElementById('stopButton').disabled = false;
        })
        .catch(err => {
            console.error('録音の許可が得られませんでした: ', err);
        });
}

function stopLiveAudio() {
    // ボタンの状態を変更
    document.getElementById('startButton').disabled = false;
    document.getElementById('stopButton').disabled = true;

    // ストリームとコンテキストを閉じる
    if (microphoneStream) {
        microphoneStream.getTracks().forEach(track => track.stop());
    }
    if (audioContext) {
        audioContext.close();
    }
}

document.addEventListener('DOMContentLoaded', () => {
    document.getElementById('startButton').addEventListener('click', startLiveAudio);
    document.getElementById('stopButton').addEventListener('click', stopLiveAudio);
});
</script>
</body>
</html>
